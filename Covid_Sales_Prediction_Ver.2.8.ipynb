{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "49534bc4",
   "metadata": {},
   "source": [
    "# Covid Sales Forecasting"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ea4a87c8",
   "metadata": {},
   "source": [
    "### 목차"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5039631b",
   "metadata": {},
   "source": [
    "#### 1. 모듈 및 데이터 임포트\n",
    "#####  <GPU 확인>\n",
    "#####  <데이터 임포트>\n",
    "<br/>\n",
    "\n",
    "#### 2. 데이터 전처리\n",
    "#####  2.1. MinMaxScaling\n",
    "#####  2.2. 데이터 연관성 분석\n",
    "#####  2.3. 이상치 처리\n",
    "#####  2.4. 데이터셋 분할\n",
    "#####  <결과기록용 데이터셋 저장>\n",
    "#####  <테스트셋 csv 저장>\n",
    "<br/>\n",
    "\n",
    "#### 3. 딥러닝\n",
    "#####  3.1. 네트워크 모델\n",
    "#####  <Plot model 저장>\n",
    "#####  3.2. 학습\n",
    "<br/>\n",
    "\n",
    "#### 4. 결과 표시\n",
    "#####  4.1. 손실 함수 그래프\n",
    "#####  <채점용 csv 저장>\n",
    "#####  4.2. 측정 성능 출력\n",
    "#####  4.3. 예측 그래프"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "79f886a9",
   "metadata": {},
   "source": [
    "##### <화면 가로 확장>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "01779336",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>.container { width:80% !important; }</style>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# 화면 가로 확장 코드 (기본 width 50%)\n",
    "from IPython.core.display import display, HTML\n",
    "display(HTML(\"<style>.container { width:80% !important; }</style>\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5914b761",
   "metadata": {},
   "source": [
    "### 1. 모듈 임포트"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4fef1b48",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np \n",
    "import pandas as pd \n",
    "import matplotlib.pyplot as plt\n",
    "from mpl_toolkits.mplot3d import Axes3D\n",
    "import seaborn as sns\n",
    "import tensorflow as tf\n",
    "import csv\n",
    "import os\n",
    "import datetime\n",
    "import h5py"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f7f69a8e",
   "metadata": {},
   "source": [
    "##### <GPU 확인>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b6295985",
   "metadata": {},
   "outputs": [],
   "source": [
    "tf.test.gpu_device_name()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9c1e9665",
   "metadata": {},
   "source": [
    "#### 최종 데이터 Import"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5d68ba68",
   "metadata": {},
   "outputs": [],
   "source": [
    "Data_Combined=pd.read_csv('./Data/2021_Data_Combined.csv', encoding='cp949')\n",
    "Data_Combined"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "82d48c93",
   "metadata": {},
   "outputs": [],
   "source": [
    "Data_Combined['Won'].max()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3fb042ae",
   "metadata": {},
   "source": [
    "### 2. 데이터 전처리"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "60c87e2c",
   "metadata": {},
   "source": [
    "#### 2.1. Min-Max Scaling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b72ea907",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import MinMaxScaler\n",
    "# 정규화 과정을 거쳐 데이터 범위를 원하는 범위로 제한. 그래프는 동일하나 손실 정도를 확인하기에 더 좋음.\n",
    "# 배치 정규화는 기울기 소멸 문제를 해결하기는 좋으나, RNN의 경우 계층별로 미니 정규화 적용이 필요해 모델이 복잡해지고 효율이 저하됨.\n",
    "Data_Combined.sort_index(ascending=False).reset_index(drop=True)\n",
    "\n",
    "scaler = MinMaxScaler()\n",
    "scale_cols = ['확진자수(양성)', '검사수', '확진자 증가량', '검사수 증가량', '18시 전 규제 인원수', '18시 후 규제 인원수', '영업 제한 시각', '평균기온(°C)', '강수여부', '일강수량(mm)', '평균 풍속(m/s)', 'Won']\n",
    "Data_scaled = scaler.fit_transform(Data_Combined[scale_cols])\n",
    "Data_scaled = pd.DataFrame(Data_scaled)\n",
    "Data_scaled.columns = scale_cols\n",
    "\n",
    "Data_scaled.insert(0, '날짜', Data_Combined['날짜'])\n",
    "Data_scaled"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "88477722",
   "metadata": {},
   "source": [
    "#### 2.2.. 데이터 연관성 분석"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "81e71bfa",
   "metadata": {},
   "outputs": [],
   "source": [
    "Data_scaled.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "38e5c5fb",
   "metadata": {},
   "outputs": [],
   "source": [
    "import scipy.stats as stats\n",
    "\n",
    "# 피어슨 stat을 이용하면 피어슨 상관계수와 p-value값이 출력되는데 상관계수는 양 or 음의 비례관계 정도를, p-value는 상관 정도를 보여준다. (0에 가까울수록 영향이 크다.)\n",
    "def P_value(dataset, c1, c2):\n",
    "    Correlation=stats.pearsonr(dataset[c1], dataset[c2])\n",
    "    print('< '+c1+'-'+c2+' >')\n",
    "    print('P-value ==>> %.3f\\n' %Correlation[1])\n",
    "\n",
    "for p in range(1, len(Data_scaled.columns)-1):\n",
    "    P_value(Data_scaled, Data_scaled.columns[p], 'Won')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4ce0ee9a",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Data_P = Data_scaled.drop([Data_scaled.columns[1], Data_scaled.columns[3], Data_scaled.columns[4], Data_scaled.columns[5], Data_scaled.columns[7], Data_scaled.columns[9]], axis=1)\n",
    "Data_P = Data_scaled.loc[:, ['날짜', '검사수', '검사수 증가량', '영업 제한 시각', '평균기온(°C)', '일강수량(mm)', 'Won']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "facb50d7",
   "metadata": {},
   "outputs": [],
   "source": [
    "Data_P"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "043d8fb9",
   "metadata": {},
   "source": [
    "#### 2.3. 이상치 처리"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "82656f2d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_outlier(df=None, column=None, weight=None):\n",
    "    quantile_5 = np.percentile(df[column].values, 5)\n",
    "    quantile_25 = np.percentile(df[column].values, 25)\n",
    "    quantile_50 = np.percentile(df[column].values, 50)\n",
    "    quantile_75 = np.percentile(df[column].values, 75)\n",
    "    quantile_95 = np.percentile(df[column].values, 95)\n",
    "    \n",
    "    IQR = quantile_75 - quantile_25\n",
    "    IQR_weight = IQR * weight\n",
    "\n",
    "    lowest_val = quantile_25-IQR_weight\n",
    "    highest_val = quantile_75+IQR_weight\n",
    "    \n",
    "    outlier_index_lowest = df[column][df[column] < quantile_5].index\n",
    "    outlier_index_low = df[column][df[column] < lowest_val].index\n",
    "    outlier_index_high = df[column][df[column] > highest_val].index\n",
    "    outlier_index_highest = df[column][df[column] > quantile_95].index\n",
    "    \n",
    "    return outlier_index_lowest, outlier_index_low, outlier_index_high, outlier_index_highest, quantile_5, quantile_25, quantile_50, quantile_75, quantile_95"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "91eba6bb",
   "metadata": {},
   "outputs": [],
   "source": [
    "WEIGHT=2.5\n",
    "Lowest_list = get_outlier(df=Data_P, column='Won', weight=WEIGHT)[0]\n",
    "Highest_list = get_outlier(df=Data_P, column='Won', weight=WEIGHT)[3]\n",
    "\n",
    "print('Lowest Outlier ==>> {}\\n'.format(Lowest_list))\n",
    "print('Low Outlier ==>> {}\\n'.format(get_outlier(df=Data_P, column='Won', weight=WEIGHT)[1]))\n",
    "print('High Outlier ==>> {}\\n'.format(get_outlier(df=Data_P, column='Won', weight=WEIGHT)[2]))\n",
    "print('Highest Outlier ==>> {}\\n'.format(Highest_list))\n",
    "\n",
    "print('5% Value ==>> {}\\n'.format(get_outlier(df=Data_P, column='Won', weight=WEIGHT)[4]))\n",
    "print('25% Value ==>> {}\\n'.format(get_outlier(df=Data_P, column='Won', weight=WEIGHT)[5]))\n",
    "print('50% Value ==>> {}\\n'.format(get_outlier(df=Data_P, column='Won', weight=WEIGHT)[6]))\n",
    "print('75% Value ==>> {}\\n'.format(get_outlier(df=Data_P, column='Won', weight=WEIGHT)[7]))\n",
    "print('95% Value ==>> {}'.format(get_outlier(df=Data_P, column='Won', weight=WEIGHT)[8]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fd6187e4",
   "metadata": {},
   "outputs": [],
   "source": [
    "WEIGHT_2R=np.sqrt(WEIGHT)\n",
    "\n",
    "for i in range(len(Lowest_list)):\n",
    "    Data_P['Won'][Lowest_list[i]] = Data_P['Won'][Lowest_list[i]]*WEIGHT_2R\n",
    "    \n",
    "for i in range(len(Highest_list)):\n",
    "    Data_P['Won'][Highest_list[i]] = Data_P['Won'][Highest_list[i]]/WEIGHT_2R"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fd009cc7",
   "metadata": {},
   "outputs": [],
   "source": [
    "high_val = get_outlier(df=Data_P, column='Won', weight=WEIGHT)[2].values.tolist()\n",
    "\n",
    "for i in range(len(high_val)):\n",
    "    Data_P['Won'][high_val[i]] = Data_P['Won'][high_val[i]]/WEIGHT_2R"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e678ecf9",
   "metadata": {},
   "outputs": [],
   "source": [
    "print('Quantity of Low Outlier ==>> {}\\n'.format(len(get_outlier(df=Data_P, column='Won', weight=WEIGHT)[1])))\n",
    "print('Quantity of High Outlier ==>> {}\\n'.format(len(get_outlier(df=Data_P, column='Won', weight=WEIGHT)[2])))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8395aaba",
   "metadata": {},
   "source": [
    "#### 2.4. 데이터셋 분할"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "91bae70e",
   "metadata": {},
   "outputs": [],
   "source": [
    "TEST_SIZE = 14\n",
    "WINDOW_SIZE = 7 # 얼마 동안의 과거 기반의 데이터에 기반하여 다음날의 값을 예측할 것인지 설정. \n",
    "BATCH_SIZE = 256\n",
    "\n",
    "train = Data_P[:-TEST_SIZE]\n",
    "test= Data_P[-TEST_SIZE:]\n",
    "test = test.reset_index(drop=True) # 인덱스 초기화"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7609ba6c",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "feature_cols = ['검사수', '검사수 증가량', '영업 제한 시각', '평균기온(°C)', '일강수량(mm)', 'Won']\n",
    "label_cols = ['Won']\n",
    "\n",
    "train_feature = train[feature_cols]\n",
    "train_label = train[label_cols]\n",
    "\n",
    "x_train, x_valid, y_train, y_valid = train_test_split(train_feature, train_label, test_size=0.3, shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "caa443a1",
   "metadata": {},
   "outputs": [],
   "source": [
    "def windowed_dataset(series, window_size, batch_size, shuffle):\n",
    "    series = tf.expand_dims(series, axis=-1)\n",
    "    ds = tf.data.Dataset.from_tensor_slices(series)\n",
    "    ds = ds.window(window_size + 1, shift=1, drop_remainder=True)\n",
    "    ds = ds.flat_map(lambda w: w.batch(window_size + 1))\n",
    "    if shuffle:\n",
    "        ds = ds.shuffle(1000)\n",
    "    ds = ds.map(lambda w: (w[:-1], w[-1]))\n",
    "    return ds.batch(batch_size).prefetch(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a19e44fb",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data = windowed_dataset(y_train, WINDOW_SIZE, BATCH_SIZE, False) # 학습도 셔플 안해야 맞는게 아닌가??\n",
    "valid_data = windowed_dataset(y_valid, WINDOW_SIZE, BATCH_SIZE, False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4c642043",
   "metadata": {},
   "outputs": [],
   "source": [
    "for data in train_data.take(1):\n",
    "    print(f'데이터셋(X) 구성(batch_size, window_size, feature갯수): {data[0].shape}')\n",
    "    print(f'데이터셋(Y) 구성(batch_size, window_size, feature갯수): {data[1].shape}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e7c8ea36",
   "metadata": {},
   "source": [
    "##### <결과기록용 데이터셋 저장>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1c070de0",
   "metadata": {},
   "outputs": [],
   "source": [
    "train\n",
    "train.to_csv('./Result/score/Learning_set.csv', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dbd71483",
   "metadata": {},
   "source": [
    "##### <평가용 csv 저장>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2b2721cc",
   "metadata": {},
   "outputs": [],
   "source": [
    "TESTSET = test['Won']\n",
    "TESTSET.to_csv('./Result/score/Test_set.csv', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0249c42f",
   "metadata": {},
   "source": [
    "### 3. 딥러닝"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "47ace4f6",
   "metadata": {},
   "source": [
    "#### 3.1. 네트워크 모델"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c11aaf45",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense, Dropout\n",
    "from tensorflow.keras.callbacks import EarlyStopping, ModelCheckpoint\n",
    "from tensorflow.keras.utils import plot_model\n",
    "import keras\n",
    "LeakyReLU=tf.keras.layers.LeakyReLU(alpha=0.01)\n",
    "\n",
    "#16-0.2-8-1\n",
    "model = Sequential([\n",
    "    Dense(8, activation='ELU', input_shape=[WINDOW_SIZE, 1]),\n",
    "    Dense(8, activation='ELU'),\n",
    "    Dense(2, activation='ELU'),\n",
    "    Dense(1)\n",
    "                    ])\n",
    "\n",
    "model.summary()\n",
    "\n",
    "model.compile(loss='mean_absolute_error', optimizer=\"Nadam\", metrics=['mae'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cd6964ab",
   "metadata": {},
   "source": [
    "##### <Plot model 저장>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "82e93e66",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "from keras.utils.vis_utils import plot_model\n",
    "import pydot\n",
    "import pydotplus\n",
    "import graphviz\n",
    "\n",
    "plot_model(model, to_file='./Result/model.png')\n",
    "plot_model(model, to_file='./Result/model_shapes.png', show_shapes=True)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e4aa6030",
   "metadata": {},
   "source": [
    "#### 3.2. 학습"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d18415fc",
   "metadata": {},
   "outputs": [],
   "source": [
    "#early_stop = EarlyStopping(monitor='val_loss', patience=20)\n",
    "\n",
    "with tf.device('/GPU:0'):\n",
    "    model_path = 'model'\n",
    "    filename = os.path.join(model_path, 'tmp_checkpoint_Covid.h5')\n",
    "    checkpoint = ModelCheckpoint(filename, monitor='val_loss', verbose=1, save_best_only=True, mode='auto')\n",
    "    history = model.fit(train_data, epochs=35, batch_size=BATCH_SIZE, validation_data=(valid_data), callbacks=[checkpoint])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "269d7721",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.load_weights(filename)\n",
    "pred = model.predict(test['Won'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3f70a61f",
   "metadata": {},
   "source": [
    "### 4. 결과 표시"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "33bddf7a",
   "metadata": {},
   "outputs": [],
   "source": [
    "try:\n",
    "    os.mkdir('./Result')\n",
    "    print('폴더 생성 완료.')\n",
    "    \n",
    "except FileExistsError:\n",
    "    print('해당 폴더가 이미 존재합니다.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "90879fb0",
   "metadata": {},
   "outputs": [],
   "source": [
    "try:\n",
    "    os.mkdir('./Result/Graph')\n",
    "    os.mkdir('./Result/Data')\n",
    "    print('폴더 생성 완료.')\n",
    "    \n",
    "except FileExistsError:\n",
    "    print('해당 폴더가 이미 존재합니다.')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4dccbb45",
   "metadata": {},
   "source": [
    "#### 4.1. 손실 함수 그래프"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d594d777",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(16, 10))\n",
    "plt.title('Model Loss Convergence Graph', size='15')\n",
    "y_tloss = history.history['loss']\n",
    "y_vloss = history.history['val_loss']\n",
    "x_len = np.arange(len(y_tloss))\n",
    "plt.xlabel('Epoch')\n",
    "plt.ylabel('Loss')\n",
    "\n",
    "plt.plot(x_len, y_tloss, \"o-\", c=\"blue\", markersize=3)\n",
    "plt.plot(x_len, y_vloss, \"o-\", c=\"red\", markersize=3)\n",
    "plt.margins(x=0.02)\n",
    "plt.legend(['Training loss', 'Validation loss'])\n",
    "plt.savefig('./Result/Graph/Model_Loss_Convergence_Graph.png')\n",
    "plt.show"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "afd501b5",
   "metadata": {},
   "outputs": [],
   "source": [
    "pred=pred.reshape(-1,1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7b27eea7",
   "metadata": {},
   "outputs": [],
   "source": [
    "pred.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "491c5314",
   "metadata": {},
   "source": [
    "##### <채점용 csv 저장>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7264cb81",
   "metadata": {},
   "outputs": [],
   "source": [
    "PRED_df = pd.DataFrame(pred)\n",
    "PRED_df.to_csv('./Result/score/Pred.csv', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "da003525",
   "metadata": {},
   "source": [
    "#### 4.2. 측정 성능 출력"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f21915c7",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import r2_score as r2\n",
    "from sklearn.metrics import mean_absolute_error as MAE\n",
    "from sklearn.metrics import mean_squared_error as MSE\n",
    "from sklearn.metrics import mean_squared_log_error as MSLE\n",
    "\n",
    "RMSE = np.sqrt(MSE(test['Won'], pred))\n",
    "R2 = r2(test['Won'], pred)\n",
    "print('r2 >> %.4f' %R2) # 1에 가까워야 좋음\n",
    "print('MAE >> %.4f' %MAE(test['Won'], pred)) # 0에 가까워야 좋음\n",
    "print('RMSE >> %.4f' %RMSE) # 0에 가까워야 좋음"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "afe21115",
   "metadata": {},
   "outputs": [],
   "source": [
    "RMSE_pct = round(1-RMSE, 5)*100\n",
    "RMSE_Percentage='RMSE Accuracy = %.3f %%' %RMSE_pct\n",
    "print(RMSE_Percentage)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "310a88fc",
   "metadata": {},
   "outputs": [],
   "source": [
    "score = round(((1-RMSE)/2 + R2/2),4)\n",
    "Final_score = 'Final Score = 0.5*r2 + 0.5*RMSE = %.4f' %score\n",
    "print(Final_score)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f9eb998c",
   "metadata": {},
   "source": [
    "#### 4.3. 예측 그래프"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "09554c4d",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(14,9))\n",
    "plt.title('Sales Forecasting during COVID-19 ', y=1.03, size='15')\n",
    "plt.suptitle(Final_score, y=0.9, fontsize=12)\n",
    "plt.plot(test['Won'], label='Actual')\n",
    "plt.plot(pred, label='Prediction')\n",
    "plt.xticks(range(0,14), labels=range(1,15))\n",
    "plt.xlabel('Days')\n",
    "plt.yticks([0, 0.0688, 0.1376, 0.2064, 0.2752, 0.344, 0.4128], \n",
    "           labels=[0, 50000, 100000, 150000, 200000, 250000, 300000])\n",
    "plt.ylabel('Won')\n",
    "plt.grid(True)\n",
    "plt.legend()\n",
    "plt.savefig('./Result/Graph/Result_Grpah.png')\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
